{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPWIYkxer/JF5EABguxhaCi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDVALxtl4A-c","executionInfo":{"status":"ok","timestamp":1747674119684,"user_tz":-480,"elapsed":3445,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"9eccc8bb-573d-4cd4-c032-60c10b35c40b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!git clone https://github.com/FareedKhan-dev/text2video-from-scratch.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CeGY0rMF4CaR","executionInfo":{"status":"ok","timestamp":1747674133245,"user_tz":-480,"elapsed":2771,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"d16e62ac-d998-49a4-a018-23cacdfc83bb"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'text2video-from-scratch'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Counting objects: 100% (56/56), done.\u001b[K\n","remote: Compressing objects: 100% (42/42), done.\u001b[K\n","remote: Total 56 (delta 8), reused 53 (delta 8), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (56/56), 4.53 MiB | 4.85 MiB/s, done.\n","Resolving deltas: 100% (8/8), done.\n"]}]},{"cell_type":"code","source":["cd text2video-from-scratch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjjulxN-4CiV","executionInfo":{"status":"ok","timestamp":1747674136042,"user_tz":-480,"elapsed":23,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"80067850-bae9-48a6-9988-a27da3fb6660"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/text2video-from-scratch/text2video-from-scratch\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3iCrIUq4CpP","executionInfo":{"status":"ok","timestamp":1747674141496,"user_tz":-480,"elapsed":2732,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"bcefdc15-2e53-45c2-9b72-7d56020b5743"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.8.1)\n","Requirement already satisfied: einops-exts in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.0.4)\n","Requirement already satisfied: rotary-embedding-torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.8.6)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.1.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (4.67.1)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.7.4.5)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.6.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.51.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.2.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses->-r requirements.txt (line 8)) (2024.11.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->-r requirements.txt (line 8)) (8.2.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->-r requirements.txt (line 8)) (1.5.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (0.31.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (0.5.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 10)) (1.6.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (2025.4.26)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (3.4.2)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (3.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (5.29.4)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (8.0.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (1.3)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (2.4.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 12)) (0.5.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 13)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 13)) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 13)) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 13)) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 13)) (0.70.15)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]->-r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (3.11.15)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 13)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 13)) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 13)) (1.20.0)\n"]}]},{"cell_type":"code","source":["# 安装kaggle包\n","!pip install -q kaggle\n","\n","# 上传你的kaggle.json文件\n","from google.colab import files\n","files.upload()  # 这会提示你上传文件，请上传从Kaggle账户获取的kaggle.json\n","\n","# 设置权限\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# 验证安装\n","!kaggle datasets list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vZKBXbJ4Cvs","outputId":"3d0a3afe-bc37-453a-8745-5714dce8fd7d","executionInfo":{"status":"error","timestamp":1747674234375,"user_tz":-480,"elapsed":30030,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}}},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-db66838d-019a-49ea-8b9d-194cdecb0c36\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-db66838d-019a-49ea-8b9d-194cdecb0c36\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4d31da0b8abb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 上传你的kaggle.json文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 这会提示你上传文件，请上传从Kaggle账户获取的kaggle.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 设置权限\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["ls -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e__iDDNS6Htb","executionInfo":{"status":"ok","timestamp":1747111499227,"user_tz":-480,"elapsed":81,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"f25e6e4d-23ca-4cc1-d7f9-9a702d274f8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34m.\u001b[0m/        \u001b[01;34mdata_generation\u001b[0m/  .gitignore   \u001b[01;34mothers\u001b[0m/           \u001b[01;34msrc\u001b[0m/\n","\u001b[01;34m..\u001b[0m/       generate.py       kaggle.json  README.md         train.py\n","\u001b[01;34mconfigs\u001b[0m/  \u001b[01;34m.git\u001b[0m/             LICENSE      requirements.txt\n"]}]},{"cell_type":"code","source":["pip install -U datasets\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mJqNhAD8VBM","executionInfo":{"status":"ok","timestamp":1747674242749,"user_tz":-480,"elapsed":2530,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"3b2ebc98-ac07-4488-f209-813ec37e6618"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"code","source":["import os\n","import subprocess\n","import zipfile\n","from pathlib import Path\n","from typing import List\n","import pandas as pd\n","from tqdm import tqdm\n","from moviepy.editor import VideoFileClip\n","from datasets import load_dataset\n","\n","\n","\n","def download_kaggle_dataset(dataset_name: str, download_dir: str) -> None:\n","    \"\"\"\n","    Downloads a dataset from Kaggle and saves it to the specified directory.\n","\n","    :param dataset_name: The name of the Kaggle dataset (e.g., 'vishnutheepb/msrvtt').\n","    :param download_dir: Directory where the dataset will be saved.\n","    \"\"\"\n","    # Make sure the directory exists\n","    Path(download_dir).mkdir(parents=True, exist_ok=True)\n","\n","    # Download dataset using Kaggle CLI\n","    print(f\"Downloading Kaggle dataset: {dataset_name}...\")\n","    command = f\"kaggle datasets download {dataset_name} -p {download_dir}\"\n","    subprocess.run(command, shell=True, check=True)\n","    print(f\"Dataset {dataset_name} downloaded to {download_dir}\")\n","def unzip_file(zip_path: str, extract_dir: str) -> None:\n","    \"\"\"\n","    Unzips a .zip file into the specified directory.\n","\n","    :param zip_path: Path to the zip file.\n","    :param extract_dir: Directory to extract files to.\n","    \"\"\"\n","    print(f\"Unzipping file: {zip_path}...\")\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_dir)\n","    print(f\"Files extracted to {extract_dir}\")\n","\n","\n","def download_hf_dataset(dataset_name: str) -> pd.DataFrame:\n","    \"\"\"\n","    Downloads a dataset from HuggingFace.\n","\n","    :param dataset_name: The name of the dataset on HuggingFace (e.g., 'AlexZigma/msr-vtt').\n","    :return: A DataFrame containing the dataset.\n","    \"\"\"\n","    print(f\"Downloading HuggingFace dataset: {dataset_name}...\")\n","    dataset = load_dataset(dataset_name, split=\"train\")\n","    # Convert the dataset to a pandas DataFrame\n","    df = pd.DataFrame(dataset)\n","    print(f\"HuggingFace dataset {dataset_name} loaded successfully.\")\n","    return df\n","\n","\n","def convert_video_to_gif(video_path: str, gif_path: str, size: tuple = (64, 64), num_frames: int = 10) -> None:\n","    \"\"\"\n","    Converts a video file (MP4) to a GIF with specified size and number of frames.\n","\n","    :param video_path: Path to the input video (MP4).\n","    :param gif_path: Path to save the output GIF.\n","    :param size: Desired size for the GIF (default is 64x64).\n","    :param num_frames: The number of frames to sample for the GIF (default is 10).\n","    \"\"\"\n","    try:\n","        # Load the video file\n","        clip = VideoFileClip(video_path)\n","\n","        # Resize the video to the desired size\n","        clip = clip.resize(height=size[1], width=size[0])\n","\n","        # Sample frames evenly from the video and convert to GIF\n","        clip = clip.subclip(0, clip.duration).resize(size).set_fps(clip.fps).set_duration(clip.duration / num_frames)\n","\n","        clip.write_gif(gif_path, program='ffmpeg')\n","\n","        print(f\"Converted {video_path} to GIF and saved as {gif_path}\")\n","    except Exception as e:\n","        print(f\"Error converting video {video_path} to GIF: {e}\")\n","\n","\n","def create_training_data(df: pd.DataFrame, videos_dir: str, output_dir: str, size: tuple = (64, 64), num_frames: int = 10) -> None:\n","    \"\"\"\n","    Creates a training folder containing GIFs and corresponding caption text files.\n","\n","    :param df: DataFrame containing video data.\n","    :param videos_dir: Directory where videos are stored.\n","    :param output_dir: Directory where the training data will be saved.\n","    :param size: Desired size for the GIF (default is 64x64).\n","    :param num_frames: The number of frames to sample for the GIF (default is 10).\n","    \"\"\"\n","    Path(output_dir).mkdir(parents=True, exist_ok=True)\n","\n","    print(\"Starting the conversion of videos to GIFs and creating caption text files...\")\n","\n","    # Use tqdm to show a progress bar while iterating over the rows of the DataFrame\n","    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Videos\", ncols=100):\n","        video_id = row['video_id']\n","        caption = row['caption']\n","\n","        # Define paths\n","        video_path = os.path.join(videos_dir, f\"{video_id}.mp4\")\n","        gif_path = os.path.join(output_dir, f\"{video_id}.gif\")\n","        caption_path = os.path.join(output_dir, f\"{video_id}.txt\")\n","\n","        # Convert video to GIF with size and frame limit\n","        convert_video_to_gif(video_path, gif_path, size=size, num_frames=num_frames)\n","\n","        # Save the caption in a text file\n","        with open(caption_path, 'w') as caption_file:\n","            caption_file.write(caption)\n","\n","    print(f\"Training data successfully created in {output_dir}\")\n","\n","def main():\n","\n","\n","    # Step 1: Download the Kaggle dataset\n","    kaggle_dataset_name = 'vishnutheepb/msrvtt'\n","    download_dir = './msrvtt_data'\n","    download_kaggle_dataset(kaggle_dataset_name, download_dir)\n","    # Step 2: Unzip the Kaggle dataset\n","    zip_file_path = os.path.join(download_dir, 'msrvtt.zip')\n","    unzip_dir = os.path.join(download_dir, 'msrvtt')\n","    unzip_file(zip_file_path, unzip_dir)\n","\n","    # Step 3: Define the path to the TrainValVideo directory where the videos are located\n","    videos_dir = os.path.join(unzip_dir, 'TrainValVideo')\n","\n","    # Step 4: Download the HuggingFace MSR-VTT dataset\n","    hf_dataset_name = 'AlexZigma/msr-vtt'\n","    df = download_hf_dataset(hf_dataset_name)\n","\n","    # Step 5: Create a training folder\n","    output_dir = '../training_data'\n","    create_training_data(df, videos_dir, output_dir, size=(64, 64), num_frames=10)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFOCSwHk4C2b","outputId":"f52f1da4-3a5f-46e1-90aa-6a6cb1e2704b","executionInfo":{"status":"error","timestamp":1747674245475,"user_tz":-480,"elapsed":451,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading Kaggle dataset: vishnutheepb/msrvtt...\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"Command 'kaggle datasets download vishnutheepb/msrvtt -p ./msrvtt_data' returned non-zero exit status 1.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-1d631425eff8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-1d631425eff8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mkaggle_dataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vishnutheepb/msrvtt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mdownload_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./msrvtt_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkaggle_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Step 2: Unzip the Kaggle dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mzip_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'msrvtt.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-1d631425eff8>\u001b[0m in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(dataset_name, download_dir)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Kaggle dataset: {dataset_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"kaggle datasets download {dataset_name} -p {download_dir}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset {dataset_name} downloaded to {download_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munzip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command 'kaggle datasets download vishnutheepb/msrvtt -p ./msrvtt_data' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["!mv /content/training_data /content/text2video-from-scratch/"],"metadata":{"id":"POjnNE9S4K0p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_CibJ5X4K6X","executionInfo":{"status":"ok","timestamp":1747673443300,"user_tz":-480,"elapsed":104,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"fd882f13-ac59-4e71-8943-cbca3ff63342"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":["!python generate.py --text \"A dog is running\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdnGpQ6A4LAC","executionInfo":{"status":"ok","timestamp":1747668273461,"user_tz":-480,"elapsed":12803,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"64b90b71-f161-43d4-8171-1c34e572e6f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-05-19 15:24:25.260945: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-05-19 15:24:25.278608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1747668265.299727  708972 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1747668265.306232  708972 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-19 15:24:25.327590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","sampling loop time step: 100% 10/10 [00:01<00:00,  9.37it/s]\n","Saved GIF: ./results/a_dog_is.gif\n"]}]},{"cell_type":"code","source":["!python generate.py --text \"A panda is eating bamboo\" --batch_size 8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lgu1yfP-4TeN","executionInfo":{"status":"ok","timestamp":1747120551877,"user_tz":-480,"elapsed":13440,"user":{"displayName":"Yixuan Luo","userId":"04813191050813052504"}},"outputId":"5714ca1c-5d38-4d60-d93e-16dceb3eac16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-05-13 07:15:43.396809: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-05-13 07:15:43.414529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1747120543.436462  708909 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1747120543.442984  708909 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-13 07:15:43.464830: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","sampling loop time step: 100% 10/10 [00:01<00:00,  9.08it/s]\n","Saved GIF: ./results/a_panda_is.gif\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yc-s8vgE4Tmi"},"execution_count":null,"outputs":[]}]}